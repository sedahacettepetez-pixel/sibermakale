# ğŸš€ UNSW-NB15 AÄŸ TabanlÄ± SaldÄ±rÄ± Tespit Sistemi (IDS)
## Tam KapsamlÄ± End-to-End Machine Learning Pipeline

---

## ğŸ“‹ Sistem Mimarisi

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UNSW-NB15 IDS PIPELINE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. VERÄ° YÃœKLEME & TEMÄ°ZLEME
   â”œâ”€ UNSW_NB15_training-set.csv (175,341 satÄ±r)
   â”œâ”€ UNSW_NB15_testing-set.csv (82,332 satÄ±r)
   â”œâ”€ Eksik deÄŸer analizi ve imputation
   â””â”€ Data type conversion ve validation

2. Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄÄ° (60+ Ã–zellik)
   â”œâ”€ Bytes Features (7)
   â”‚   â”œâ”€ bytes_total, bytes_ratio_sd/ds
   â”‚   â”œâ”€ bytes_per_sec, bytes_per_pkt
   â”‚   â””â”€ bytes_mean_size, bytes_size_diff
   â”œâ”€ Packet Features (6)
   â”‚   â”œâ”€ pkts_total, pkts_ratio_sd
   â”‚   â”œâ”€ pkts_per_sec, pkts_density
   â”‚   â””â”€ spkts_rate, dpkts_rate
   â”œâ”€ Network Load & Jitter (6)
   â”‚   â”œâ”€ load_total, load_ratio
   â”‚   â”œâ”€ jitter_total, jitter_ratio
   â”‚   â””â”€ loss_total, loss_ratio
   â”œâ”€ State-TTL Ä°liÅŸkileri (3)
   â”‚   â”œâ”€ state_ttl_intensity
   â”‚   â”œâ”€ state_ttl_deviation
   â”‚   â””â”€ ct_ratio_srv_dst
   â”œâ”€ Port Analizi (5)
   â”‚   â”œâ”€ sport/dsport_bucket (well-known/registered/dynamic)
   â”‚   â”œâ”€ sport/dsport_service_type (web/email/dns/ftp/etc)
   â”‚   â””â”€ same_port_bucket
   â”œâ”€ Ä°nteraksiyon Features (2)
   â”‚   â”œâ”€ proto_service (Protocol Ã— Service)
   â”‚   â””â”€ proto_state (Protocol Ã— State)
   â””â”€ Temporal Features (5)
       â”œâ”€ hour, hour_sin, hour_cos
       â”œâ”€ is_business_hour
       â””â”€ is_night

3. CROSS-VALIDATION STRATEJISI
   â”œâ”€ Host-Based GroupKFold (5-fold)
   â”œâ”€ Veri SÄ±zÄ±ntÄ±sÄ± Engelleme: srcip + dstip gruplama
   â”œâ”€ Stratified sampling per attack category
   â””â”€ Leakage detection ve validation

4. Ã–N Ä°ÅLEME PIPELINE
   â”œâ”€ Categorical Encoding: OneHotEncoder
   â”œâ”€ Numeric Scaling: RobustScaler
   â”œâ”€ Ä°mbalanced Data Handling: SMOTENC (k=5)
   â”œâ”€ Feature Selection: Variance Threshold
   â””â”€ Outlier Detection: IsolationForest (opsiyonel)

5. MODEL EÄÄ°TÄ°MÄ° (5-Fold CV)
   â”œâ”€ LightGBM
   â”‚   â”œâ”€ learning_rate: 0.05
   â”‚   â”œâ”€ n_estimators: 500 (early_stopping)
   â”‚   â”œâ”€ max_depth: 10
   â”‚   â”œâ”€ num_leaves: 64
   â”‚   â””â”€ class_weight: balanced
   â”œâ”€ XGBoost
   â”‚   â”œâ”€ learning_rate: 0.05
   â”‚   â”œâ”€ n_estimators: 500
   â”‚   â”œâ”€ max_depth: 8
   â”‚   â”œâ”€ subsample: 0.8
   â”‚   â””â”€ scale_pos_weight: auto
   â”œâ”€ CatBoost
   â”‚   â”œâ”€ learning_rate: 0.05
   â”‚   â”œâ”€ iterations: 500
   â”‚   â”œâ”€ depth: 8
   â”‚   â”œâ”€ auto_class_weights: Balanced
   â”‚   â””â”€ task_type: GPU (Colab'da)
   â””â”€ TabTransformer (PyTorch)
       â”œâ”€ Embedding dim: 32
       â”œâ”€ Transformer layers: 6
       â”œâ”€ Attention heads: 8
       â”œâ”€ FFN dim: 128
       â””â”€ Dropout: 0.1

6. ENSEMBLE METHODS
   â”œâ”€ Soft Voting Classifier
   â”‚   â””â”€ Weights: [0.3, 0.3, 0.2, 0.2] (LGBM, XGB, Cat, TabTr)
   â”œâ”€ Stacking Classifier
   â”‚   â”œâ”€ Level-0: LightGBM, XGBoost, CatBoost, TabTransformer
   â”‚   â”œâ”€ Level-1: Logistic Regression (calibrated)
   â”‚   â””â”€ cv: 3-fold stratified
   â””â”€ Weighted Average (Optimized)
       â””â”€ Optuna HPO for optimal weights

7. MODEL KALÄ°BRASYONU
   â”œâ”€ Platt Scaling (sigmoid-based)
   â”œâ”€ Isotonic Regression (non-parametric)
   â”œâ”€ Calibration Curves (reliability diagrams)
   â””â”€ Brier Score evaluation

8. THRESHOLD OPTÄ°MÄ°ZASYONU
   â”œâ”€ F1-Maximization threshold search
   â”œâ”€ Precision-Recall trade-off analysis
   â”œâ”€ Class-specific thresholds (multi-class)
   â””â”€ Cost-sensitive threshold selection

9. MODEL DEÄERLENDÄ°RME
   â”œâ”€ Metrikler
   â”‚   â”œâ”€ Macro/Weighted F1-Score
   â”‚   â”œâ”€ Precision, Recall, Accuracy
   â”‚   â”œâ”€ OVR PR-AUC (One-vs-Rest)
   â”‚   â”œâ”€ ROC-AUC (multi-class)
   â”‚   â”œâ”€ Confusion Matrix (9Ã—9 sÄ±nÄ±f)
   â”‚   â””â”€ Per-class metrics (support, F1, precision, recall)
   â”œâ”€ GÃ¶rselleÅŸtirmeler (35+ grafik)
   â”‚   â”œâ”€ Confusion Matrices
   â”‚   â”œâ”€ PR/ROC Curves (per-class)
   â”‚   â”œâ”€ Feature Importance (GAIN, SPLIT, SHAP)
   â”‚   â”œâ”€ Calibration Curves
   â”‚   â”œâ”€ Learning Curves
   â”‚   â””â”€ Model Comparison (Radar, Boxplot, Bar)
   â””â”€ Ä°statistiksel Testler
       â”œâ”€ McNemar's test (model pairs)
       â”œâ”€ Friedman test (multiple models)
       â””â”€ Wilcoxon signed-rank test

10. AÃ‡IKLANABÄ°LÄ°RLÄ°K (EXPLAINABILITY)
    â”œâ”€ SHAP Analysis
    â”‚   â”œâ”€ TreeExplainer (for GBDT models)
    â”‚   â”œâ”€ Summary plots (global importance)
    â”‚   â”œâ”€ Dependence plots (feature interactions)
    â”‚   â”œâ”€ Waterfall plots (instance-level)
    â”‚   â””â”€ Force plots (per-prediction)
    â”œâ”€ Feature Importance Comparison
    â”‚   â”œâ”€ GAIN-based importance
    â”‚   â”œâ”€ SPLIT-based importance
    â”‚   â”œâ”€ Permutation importance
    â”‚   â””â”€ SHAP importance
    â”œâ”€ LIME (Local Interpretable Model-agnostic)
    â””â”€ Partial Dependence Plots (PDP)

11. PERFORMANS PROFÄ°LÄ°NG
    â”œâ”€ Training Time (per model, per fold)
    â”œâ”€ Inference Time (ms per sample)
    â”œâ”€ Memory Consumption (peak RAM, GPU)
    â”œâ”€ Model Size (disk space)
    â””â”€ Throughput (samples/second)

12. FEDERATED LEARNING (Experimental)
    â”œâ”€ FedAvg Algorithm
    â”œâ”€ Local model training (per client)
    â”œâ”€ Gradient aggregation
    â”œâ”€ Privacy preservation (Differential Privacy)
    â””â”€ Communication efficiency

13. CROSS-DATASET EVALUATIONÅŸ
    â”œâ”€ Test on CIC-IDS2017
    â”œâ”€ Test on NSL-KDD
    â”œâ”€ Domain adaptation metrics
    â””â”€ Transfer learning analysis

14. OTOMATIK RAPOR OLUÅTURMA
    â”œâ”€ Markdown Report
    â”‚   â”œâ”€ Executive Summary
    â”‚   â”œâ”€ Methodology
    â”‚   â”œâ”€ Results & Tables
    â”‚   â”œâ”€ Visualizations
    â”‚   â””â”€ Conclusions
    â”œâ”€ PDF Export (via pandoc)
    â”œâ”€ DOCX Export (for Word)
    â”œâ”€ LaTeX Tables (for publications)
    â””â”€ HTML Dashboard (interactive)

15. REPRODUCIBILITY
    â”œâ”€ Fixed random seeds (42)
    â”œâ”€ Environment snapshot (requirements.txt)
    â”œâ”€ Configuration versioning (config.json)
    â”œâ”€ Model checkpoints (.pkl, .pt)
    â”œâ”€ Data versioning (MD5 hashes)
    â””â”€ Experiment tracking (MLflow compatible)
```

---

## ğŸ“Š Ã‡IKTI DOSYALARI

### Tablolar (50+ CSV)
```
artifacts/tables/
â”œâ”€â”€ eda/
â”‚   â”œâ”€â”€ data_inventory.csv
â”‚   â”œâ”€â”€ eda_overview.csv
â”‚   â”œâ”€â”€ summary_numeric.csv
â”‚   â”œâ”€â”€ summary_categorical.csv
â”‚   â”œâ”€â”€ correlation_matrix.csv
â”‚   â””â”€â”€ feature_catalog_comprehensive.csv
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ imputation_report.csv
â”‚   â”œâ”€â”€ processed_schema.csv
â”‚   â”œâ”€â”€ smotenc_results.csv
â”‚   â””â”€â”€ class_balance_before_after.csv
â”œâ”€â”€ cv/
â”‚   â”œâ”€â”€ fold_sizes.csv
â”‚   â”œâ”€â”€ leakage_checks.csv
â”‚   â””â”€â”€ fold_distribution.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ lgbm_cv_scores.csv
â”‚   â”œâ”€â”€ lgbm_preds.csv
â”‚   â”œâ”€â”€ lgbm_probas.csv
â”‚   â”œâ”€â”€ lgbm_feature_importance.csv
â”‚   â”œâ”€â”€ xgb_cv_scores.csv
â”‚   â”œâ”€â”€ xgb_preds.csv
â”‚   â”œâ”€â”€ xgb_probas.csv
â”‚   â”œâ”€â”€ xgb_feature_importance.csv
â”‚   â”œâ”€â”€ catboost_cv_scores.csv
â”‚   â”œâ”€â”€ catboost_preds.csv
â”‚   â”œâ”€â”€ catboost_feature_importance.csv
â”‚   â”œâ”€â”€ tabtransformer_cv_scores.csv
â”‚   â””â”€â”€ tabtransformer_preds.csv
â”œâ”€â”€ ensemble/
â”‚   â”œâ”€â”€ soft_voting_results.csv
â”‚   â”œâ”€â”€ stacking_results.csv
â”‚   â””â”€â”€ ensemble_comparison.csv
â”œâ”€â”€ calibration/
â”‚   â”œâ”€â”€ platt_calibration_results.csv
â”‚   â”œâ”€â”€ isotonic_calibration_results.csv
â”‚   â””â”€â”€ brier_scores.csv
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ main_results.csv
â”‚   â”œâ”€â”€ model_comparison_detailed.csv
â”‚   â”œâ”€â”€ per_class_metrics_all.csv
â”‚   â”œâ”€â”€ confusion_matrices/
â”‚   â”‚   â”œâ”€â”€ lgbm_cm.csv
â”‚   â”‚   â”œâ”€â”€ xgb_cm.csv
â”‚   â”‚   â”œâ”€â”€ catboost_cm.csv
â”‚   â”‚   â””â”€â”€ ensemble_cm.csv
â”‚   â””â”€â”€ statistical_tests.csv
â”œâ”€â”€ shap/
â”‚   â”œâ”€â”€ shap_values.csv
â”‚   â”œâ”€â”€ shap_importance.csv
â”‚   â””â”€â”€ shap_interaction_values.csv
â”œâ”€â”€ profiling/
â”‚   â”œâ”€â”€ training_times.csv
â”‚   â”œâ”€â”€ inference_times.csv
â”‚   â”œâ”€â”€ memory_usage.csv
â”‚   â””â”€â”€ model_sizes.csv
â””â”€â”€ reproducibility/
    â”œâ”€â”€ reproducibility_manifest.csv
    â”œâ”€â”€ config_snapshot.json
    â””â”€â”€ data_md5_hashes.csv
```

### Grafikler (50+ PNG @ 300 DPI)
```
artifacts/figs/
â”œâ”€â”€ eda/
â”‚   â”œâ”€â”€ target_binary_dist.png
â”‚   â”œâ”€â”€ target_multi_dist.png
â”‚   â”œâ”€â”€ numeric_distributions.png
â”‚   â”œâ”€â”€ correlation_heatmap.png
â”‚   â”œâ”€â”€ class_distribution_per_fold.png
â”‚   â”œâ”€â”€ proto_distribution.png
â”‚   â”œâ”€â”€ service_distribution.png
â”‚   â””â”€â”€ port_analysis.png
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ lgbm/
â”‚   â”‚   â”œâ”€â”€ cm_lgbm.png
â”‚   â”‚   â”œâ”€â”€ pr_curve_lgbm.png
â”‚   â”‚   â”œâ”€â”€ roc_curve_lgbm.png
â”‚   â”‚   â”œâ”€â”€ feature_importance_lgbm.png
â”‚   â”‚   â”œâ”€â”€ learning_curve_lgbm.png
â”‚   â”‚   â””â”€â”€ calibration_lgbm.png
â”‚   â”œâ”€â”€ xgb/
â”‚   â”‚   â”œâ”€â”€ cm_xgb.png
â”‚   â”‚   â”œâ”€â”€ pr_curve_xgb.png
â”‚   â”‚   â”œâ”€â”€ roc_curve_xgb.png
â”‚   â”‚   â””â”€â”€ feature_importance_xgb.png
â”‚   â”œâ”€â”€ catboost/
â”‚   â”‚   â”œâ”€â”€ cm_catboost.png
â”‚   â”‚   â”œâ”€â”€ pr_curve_catboost.png
â”‚   â”‚   â””â”€â”€ feature_importance_catboost.png
â”‚   â””â”€â”€ tabtransformer/
â”‚       â”œâ”€â”€ training_loss.png
â”‚       â”œâ”€â”€ validation_metrics.png
â”‚       â””â”€â”€ attention_weights.png
â”œâ”€â”€ ensemble/
â”‚   â”œâ”€â”€ ensemble_cm.png
â”‚   â”œâ”€â”€ ensemble_pr_roc.png
â”‚   â””â”€â”€ ensemble_comparison_radar.png
â”œâ”€â”€ calibration/
â”‚   â”œâ”€â”€ calibration_curves_all_models.png
â”‚   â”œâ”€â”€ reliability_diagrams.png
â”‚   â””â”€â”€ threshold_optimization.png
â”œâ”€â”€ comparison/
â”‚   â”œâ”€â”€ model_comparison_radar.png
â”‚   â”œâ”€â”€ model_comparison_boxplot.png
â”‚   â”œâ”€â”€ feature_importance_comparison.png
â”‚   â”œâ”€â”€ training_time_comparison.png
â”‚   â””â”€â”€ f1_score_progression.png
â”œâ”€â”€ shap/
â”‚   â”œâ”€â”€ shap_summary.png
â”‚   â”œâ”€â”€ shap_dependence_plots/ (10+ plots)
â”‚   â”œâ”€â”€ shap_waterfall.png
â”‚   â””â”€â”€ shap_force_plots.png
â””â”€â”€ profiling/
    â”œâ”€â”€ memory_timeline.png
    â”œâ”€â”€ inference_time_boxplot.png
    â””â”€â”€ throughput_comparison.png
```

---

## ğŸš€ KULLANIM

### Google Colab'da:

```python
# 1. Projeyi Klonla
!git clone -b claude/unsw-nb15-setup-config-01DEmKoC2eHKvoYkAuYHsr8a \
  https://github.com/sedahacettepetez-pixel/sibermakale.git

%cd sibermakale

# 2. GPU Aktif Et
# Runtime â†’ Change runtime type â†’ GPU (T4)

# 3. Paketleri YÃ¼kle
!pip install -q -r requirements.txt

# 4. Veriyi Ä°ndir
from google.colab import files
uploaded = files.upload()  # kaggle.json yÃ¼kle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d mrwellsdavid/unsw-nb15
!unzip -q unsw-nb15.zip -d data/

# 5. TÃœM HÃœCRELERÄ° Ã‡ALIÅTIR
# Run All Cells

# 6. SonuÃ§larÄ± Ä°ndir
!zip -r results.zip artifacts/
files.download('results.zip')
```

### Lokal'de:

```bash
git clone -b claude/unsw-nb15-setup-config-01DEmKoC2eHKvoYkAuYHsr8a \
  https://github.com/sedahacettepetez-pixel/sibermakale.git
cd sibermakale
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
jupyter notebook unsw_nb15_analysis.ipynb
```

---

## ğŸ“ˆ BEKLENEN PERFORMANS

| Model | Macro F1 | PR-AUC | Accuracy | Training Time |
|-------|----------|--------|----------|---------------|
| LightGBM | ~0.85 | ~0.87 | ~0.92 | ~120s |
| XGBoost | ~0.84 | ~0.86 | ~0.91 | ~180s |
| CatBoost | ~0.85 | ~0.87 | ~0.92 | ~150s |
| TabTransformer | ~0.82 | ~0.84 | ~0.90 | ~600s |
| **Ensemble (Stacking)** | **~0.87** | **~0.89** | **~0.93** | N/A |

---

## ğŸ”¬ AKADEMÄ°K KULLANIM

### Makale Ä°Ã§in Tablolar:

- **Table 1**: Dataset Statistics â†’ `data_inventory.csv`
- **Table 2**: Feature Engineering â†’ `feature_catalog_comprehensive.csv`
- **Table 3**: Model Comparison â†’ `model_comparison_detailed.csv`
- **Table 4**: Per-Class Metrics â†’ `per_class_metrics_all.csv`
- **Table 5**: Confusion Matrix â†’ `confusion_matrices/*.csv`

### Makale Ä°Ã§in FigÃ¼rler:

- **Figure 1**: System Architecture â†’ (manuel Ã§izim)
- **Figure 2**: Feature Correlation â†’ `correlation_heatmap.png`
- **Figure 3**: Confusion Matrices â†’ `models/*/cm_*.png`
- **Figure 4**: PR/ROC Curves â†’ `models/*/pr_roc_*.png`
- **Figure 5**: Model Comparison â†’ `comparison/model_comparison_radar.png`
- **Figure 6**: SHAP Summary â†’ `shap/shap_summary.png`
- **Figure 7**: Calibration â†’ `calibration/calibration_curves_all_models.png`

---

## ğŸ“Œ Ã–NEMLÄ° NOTLAR

1. **GPU KullanÄ±mÄ±**: CatBoost ve TabTransformer iÃ§in GPU ÅŸiddetle tavsiye edilir
2. **Bellek**: En az 16GB RAM gerekli (tam veri seti iÃ§in)
3. **SÃ¼re**: TÃ¼m pipeline ~2-3 saat (GPU ile), ~6-8 saat (CPU ile)
4. **Disk**: ~5GB boÅŸ alan (artifacts iÃ§in)
5. **Reproducibility**: Her Ã§alÄ±ÅŸtÄ±rmada aynÄ± sonuÃ§lar iÃ§in seed=42 sabit

---

## ğŸ› ï¸ TEKNÄ°K DETAYLAR

### Veri SÄ±zÄ±ntÄ±sÄ± Engelleme:
- Host-based GroupKFold ile aynÄ± IP Ã§iftleri farklÄ± foldlara dÃ¼ÅŸmez
- Temporal leakage yoktur (time-based features kullanÄ±lsa da)
- Test set strict isolation

### Ä°mbalanced Data Stratejisi:
- SMOTENC (k=5) ile oversampling
- Class weights kullanÄ±mÄ±
- Focal loss (CatBoost iÃ§in)
- Stratified sampling

### Hyperparameter Optimization:
- Optuna ile Bayesian optimization
- Cross-validation iÃ§inde
- Pruning stratejisi (MedianPruner)
- Multi-objective optimization (F1 + PR-AUC)

---

**HazÄ±rlayan:** UNSW-NB15 Research Team
**Versiyon:** 2.0 - Comprehensive Edition
**Tarih:** 2025-11-15
**Branch:** `claude/unsw-nb15-setup-config-01DEmKoC2eHKvoYkAuYHsr8a`
